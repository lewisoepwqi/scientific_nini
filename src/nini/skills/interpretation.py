"""ç»Ÿè®¡ç»“æœæ™ºèƒ½è§£è¯»æ¨¡å—ã€‚

æ ¹æ®ç»Ÿè®¡æ£€éªŒç»“æœè‡ªåŠ¨ç”Ÿæˆå®é™…æ„ä¹‰è§£è¯»ï¼Œå¸®åŠ©ç”¨æˆ·ç†è§£ç»Ÿè®¡ç»“æœã€‚
"""

from __future__ import annotations

from typing import Any


class ResultInterpreter:
    """ç»Ÿè®¡ç»“æœè§£è¯»å™¨ã€‚

    é’ˆå¯¹ä¸åŒç±»å‹çš„ç»Ÿè®¡æ£€éªŒç»“æœï¼Œç”ŸæˆåŒ…å«ç»Ÿè®¡æ„ä¹‰å’Œå®é™…æ„ä¹‰çš„è§£è¯»æ–‡æœ¬ã€‚
    """

    @staticmethod
    def interpret_t_test(result: dict[str, Any]) -> str:
        """è§£è¯» t æ£€éªŒç»“æœã€‚

        Args:
            result: t_test æŠ€èƒ½è¿”å›çš„ data å­—æ®µ

        Returns:
            è§£è¯»æ–‡æœ¬
        """
        test_type = result.get("test_type", "t æ£€éªŒ")
        p_value = result.get("p_value", 1.0)
        significant = result.get("significant", False)
        t_stat = result.get("t_statistic", 0.0)

        parts = [f"ã€{test_type}è§£è¯»ã€‘"]

        # ç»Ÿè®¡æ˜¾è‘—æ€§è§£è¯»
        if significant:
            parts.append(f"ç»“æœå…·æœ‰ç»Ÿè®¡å­¦æ˜¾è‘—æ€§ (p = {p_value:.4f} < 0.05)ã€‚")
        else:
            parts.append(f"ç»“æœä¸å…·æœ‰ç»Ÿè®¡å­¦æ˜¾è‘—æ€§ (p = {p_value:.4f} >= 0.05)ã€‚")

        # æ ¹æ®æ£€éªŒç±»å‹è§£è¯»
        if "ç‹¬ç«‹æ ·æœ¬" in test_type or "é…å¯¹æ ·æœ¬" in test_type:
            mean1 = result.get("mean1")
            mean2 = result.get("mean2")
            cohens_d = result.get("cohens_d")

            if mean1 is not None and mean2 is not None:
                diff = mean1 - mean2
                direction = "é«˜äº" if diff > 0 else "ä½äº"
                parts.append(f"ç¬¬ä¸€ç»„å‡å€¼ ({mean1:.3f}) {direction}ç¬¬äºŒç»„å‡å€¼ ({mean2:.3f})ï¼Œå·®å€¼ä¸º {abs(diff):.3f}ã€‚")

            # æ•ˆåº”é‡è§£è¯»
            if cohens_d is not None:
                effect_size = ResultInterpreter._interpret_cohens_d(abs(cohens_d))
                parts.append(f"æ•ˆåº”é‡ Cohen's d = {cohens_d:.3f}ï¼Œå±äº{effect_size}ã€‚")

        elif "å•æ ·æœ¬" in test_type:
            mean = result.get("mean")
            test_value = result.get("test_value")
            if mean is not None and test_value is not None:
                diff = mean - test_value
                direction = "é«˜äº" if diff > 0 else "ä½äº"
                parts.append(f"æ ·æœ¬å‡å€¼ ({mean:.3f}) {direction}æ£€éªŒå€¼ ({test_value:.3f})ï¼Œå·®å€¼ä¸º {abs(diff):.3f}ã€‚")

        # å®é™…æ„ä¹‰æ€»ç»“
        if significant:
            parts.append("ğŸ“Š å®é™…æ„ä¹‰ï¼šä¸¤ç»„ä¹‹é—´å­˜åœ¨ç»Ÿè®¡å­¦å·®å¼‚ï¼Œè¯¥ç»“æœä¸å¤ªå¯èƒ½æ˜¯éšæœºæ³¢åŠ¨å¯¼è‡´çš„ã€‚")
        else:
            parts.append("ğŸ“Š å®é™…æ„ä¹‰ï¼šæœªèƒ½æ£€æµ‹åˆ°ä¸¤ç»„ä¹‹é—´çš„ç»Ÿè®¡å­¦å·®å¼‚ã€‚å¯èƒ½åŸå› ï¼š1) ç¡®å®æ— å·®å¼‚ï¼›2) æ ·æœ¬é‡ä¸è¶³ï¼›3) æ•ˆåº”é‡è¾ƒå°ã€‚")

        return "\n".join(parts)

    @staticmethod
    def interpret_anova(result: dict[str, Any]) -> str:
        """è§£è¯» ANOVA ç»“æœã€‚

        Args:
            result: anova æŠ€èƒ½è¿”å›çš„ data å­—æ®µ

        Returns:
            è§£è¯»æ–‡æœ¬
        """
        p_value = result.get("p_value", 1.0)
        significant = result.get("significant", False)
        f_stat = result.get("f_statistic", 0.0)
        eta_squared = result.get("eta_squared")
        n_groups = result.get("n_groups", 0)

        parts = ["ã€å•å› ç´ æ–¹å·®åˆ†æ(ANOVA)è§£è¯»ã€‘"]

        # ç»Ÿè®¡æ˜¾è‘—æ€§è§£è¯»
        if significant:
            parts.append(f"ç»“æœå…·æœ‰ç»Ÿè®¡å­¦æ˜¾è‘—æ€§ (F = {f_stat:.3f}, p = {p_value:.4f} < 0.05)ã€‚")
            parts.append(f"è¿™è¡¨æ˜ {n_groups} ä¸ªç»„çš„å‡å€¼ä¸­è‡³å°‘æœ‰ä¸€ç»„ä¸å…¶ä»–ç»„å­˜åœ¨æ˜¾è‘—å·®å¼‚ã€‚")
        else:
            parts.append(f"ç»“æœä¸å…·æœ‰ç»Ÿè®¡å­¦æ˜¾è‘—æ€§ (F = {f_stat:.3f}, p = {p_value:.4f} >= 0.05)ã€‚")
            parts.append(f"æœªèƒ½æ£€æµ‹åˆ° {n_groups} ä¸ªç»„ä¹‹é—´çš„æ˜¾è‘—å·®å¼‚ã€‚")

        # æ•ˆåº”é‡è§£è¯»
        if eta_squared is not None:
            effect_size = ResultInterpreter._interpret_eta_squared(eta_squared)
            parts.append(f"æ•ˆåº”é‡ Î·Â² = {eta_squared:.3f}ï¼Œå±äº{effect_size}ã€‚")

        # äº‹åæ£€éªŒè§£è¯»
        post_hoc = result.get("post_hoc", [])
        if post_hoc and significant:
            parts.append("\nã€Tukey HSD äº‹åæ£€éªŒç»“æœã€‘")
            significant_pairs = [p for p in post_hoc if p.get("significant")]
            if significant_pairs:
                parts.append(f"å‘ç° {len(significant_pairs)} ç»„æ˜¾è‘—å·®å¼‚ï¼š")
                for pair in significant_pairs:
                    g1, g2 = pair.get("group1"), pair.get("group2")
                    diff = pair.get("mean_diff", 0)
                    p = pair.get("p_value", 1.0)
                    parts.append(f"  - {g1} vs {g2}: å‡å€¼å·® = {diff:.3f}, p = {p:.4f}")
            else:
                parts.append("äº‹åæ£€éªŒæœªå‘ç°å…·ä½“å“ªäº›ç»„ä¹‹é—´å­˜åœ¨æ˜¾è‘—å·®å¼‚ã€‚")

        # å®é™…æ„ä¹‰æ€»ç»“
        if significant:
            parts.append("\nğŸ“Š å®é™…æ„ä¹‰ï¼šä¸åŒç»„åˆ«é—´å­˜åœ¨çœŸå®çš„å‡å€¼å·®å¼‚ã€‚å»ºè®®ç»“åˆäº‹åæ£€éªŒç»“æœï¼Œç¡®å®šå…·ä½“å“ªäº›ç»„ä¹‹é—´å­˜åœ¨å·®å¼‚ï¼Œå¹¶è€ƒè™‘æ•ˆåº”é‡å¤§å°åˆ¤æ–­å®é™…é‡è¦æ€§ã€‚")
        else:
            parts.append("\nğŸ“Š å®é™…æ„ä¹‰ï¼šå„ç»„å‡å€¼åœ¨ç»Ÿè®¡ä¸Šæ— æ˜¾è‘—å·®å¼‚ã€‚å¯èƒ½åŸå› ï¼š1) ç»„é—´ç¡®å®æ— å·®å¼‚ï¼›2) ç»„å†…å˜å¼‚è¾ƒå¤§ï¼›3) æ ·æœ¬é‡ä¸è¶³ã€‚å»ºè®®æ£€æŸ¥æ•°æ®åˆ†å¸ƒæˆ–å¢åŠ æ ·æœ¬é‡ã€‚")

        return "\n".join(parts)

    @staticmethod
    def interpret_correlation(result: dict[str, Any]) -> str:
        """è§£è¯»ç›¸å…³åˆ†æç»“æœã€‚

        Args:
            result: correlation æŠ€èƒ½è¿”å›çš„ data å­—æ®µ

        Returns:
            è§£è¯»æ–‡æœ¬
        """
        method = result.get("method", "pearson")
        sample_size = result.get("sample_size", 0)
        corr_matrix = result.get("correlation_matrix", {})
        pvalue_matrix = result.get("pvalue_matrix", {})

        parts = [f"ã€{method.title()} ç›¸å…³åˆ†æè§£è¯»ã€‘"]
        parts.append(f"æ ·æœ¬é‡ n = {sample_size}")

        # æå–æ‰€æœ‰å˜é‡å¯¹çš„ç›¸å…³æ€§
        variables = list(corr_matrix.keys())
        if len(variables) < 2:
            parts.append("å˜é‡æ•°é‡ä¸è¶³ï¼Œæ— æ³•è®¡ç®—ç›¸å…³æ€§ã€‚")
            return "\n".join(parts)

        parts.append("\nã€å˜é‡é—´ç›¸å…³æ€§ã€‘")
        interpretations = []

        for i, var1 in enumerate(variables):
            for var2 in variables[i + 1 :]:
                corr = corr_matrix.get(var1, {}).get(var2)
                pval = pvalue_matrix.get(var1, {}).get(var2)

                if corr is not None and pval is not None:
                    sig_text = "æ˜¾è‘—" if pval < 0.05 else "ä¸æ˜¾è‘—"
                    strength = ResultInterpreter._interpret_correlation_strength(abs(corr))
                    direction = "æ­£" if corr > 0 else "è´Ÿ"

                    interpretations.append(
                        f"  - {var1} â†” {var2}: r = {corr:.3f} ({direction}ç›¸å…³, {strength}, p = {pval:.4f}, {sig_text})"
                    )

        parts.extend(interpretations)

        # æ‰¾å‡ºæœ€å¼ºç›¸å…³
        max_corr = 0
        max_pair = None
        for i, var1 in enumerate(variables):
            for var2 in variables[i + 1 :]:
                corr = abs(corr_matrix.get(var1, {}).get(var2, 0))
                if corr > max_corr:
                    max_corr = corr
                    max_pair = (var1, var2)

        if max_pair and max_corr > 0.3:
            parts.append(f"\nğŸ“Š æœ€å¼ºç›¸å…³ï¼š{max_pair[0]} ä¸ {max_pair[1]} (|r| = {max_corr:.3f})")

        # æ–¹æ³•è¯´æ˜
        if method == "pearson":
            parts.append("\nğŸ’¡ è¯´æ˜ï¼šPearson ç›¸å…³ç³»æ•°è¡¡é‡çº¿æ€§å…³ç³»ï¼Œå–å€¼èŒƒå›´ [-1, 1]ã€‚æ³¨æ„ï¼šç›¸å…³æ€§ä¸ç­‰äºå› æœæ€§ã€‚")
        elif method == "spearman":
            parts.append("\nğŸ’¡ è¯´æ˜ï¼šSpearman ç­‰çº§ç›¸å…³ç³»æ•°è¡¡é‡å•è°ƒå…³ç³»ï¼Œå¯¹å¼‚å¸¸å€¼æ›´ç¨³å¥ã€‚æ³¨æ„ï¼šç›¸å…³æ€§ä¸ç­‰äºå› æœæ€§ã€‚")
        elif method == "kendall":
            parts.append("\nğŸ’¡ è¯´æ˜ï¼šKendall ç­‰çº§ç›¸å…³ç³»æ•°è¡¡é‡ä¸€è‡´æ€§ï¼Œé€‚ç”¨äºå°æ ·æœ¬ã€‚æ³¨æ„ï¼šç›¸å…³æ€§ä¸ç­‰äºå› æœæ€§ã€‚")

        return "\n".join(parts)

    @staticmethod
    def interpret_regression(result: dict[str, Any]) -> str:
        """è§£è¯»å›å½’åˆ†æç»“æœã€‚

        Args:
            result: regression æŠ€èƒ½è¿”å›çš„ data å­—æ®µ

        Returns:
            è§£è¯»æ–‡æœ¬
        """
        r_squared = result.get("r_squared", 0.0)
        adjusted_r2 = result.get("adjusted_r_squared")
        f_stat = result.get("f_statistic")
        f_pvalue = result.get("f_pvalue")
        coefficients = result.get("coefficients", {})
        n_obs = result.get("n_observations", 0)

        parts = ["ã€çº¿æ€§å›å½’åˆ†æè§£è¯»ã€‘"]
        parts.append(f"æ ·æœ¬é‡ n = {n_obs}")

        # æ¨¡å‹æ•´ä½“æ˜¾è‘—æ€§
        if f_pvalue is not None:
            if f_pvalue < 0.05:
                parts.append(f"å›å½’æ¨¡å‹æ•´ä½“æ˜¾è‘— (F = {f_stat:.3f}, p = {f_pvalue:.4f} < 0.05)ã€‚")
            else:
                parts.append(f"å›å½’æ¨¡å‹æ•´ä½“ä¸æ˜¾è‘— (F = {f_stat:.3f}, p = {f_pvalue:.4f} >= 0.05)ã€‚")

        # RÂ² è§£è¯»
        parts.append(f"RÂ² = {r_squared:.4f}ï¼Œè¡¨ç¤ºè‡ªå˜é‡å¯ä»¥è§£é‡Šå› å˜é‡ {r_squared * 100:.2f}% çš„å˜å¼‚ã€‚")
        if adjusted_r2 is not None:
            parts.append(f"è°ƒæ•´ RÂ² = {adjusted_r2:.4f}ï¼ˆè€ƒè™‘è‡ªå˜é‡ä¸ªæ•°åçš„ä¿®æ­£å€¼ï¼‰ã€‚")

        # æ•ˆåº”é‡è§£è¯»
        r2_effect = ResultInterpreter._interpret_r_squared(r_squared)
        parts.append(f"æ¨¡å‹è§£é‡ŠåŠ›ï¼š{r2_effect}")

        # ç³»æ•°è§£è¯»
        parts.append("\nã€å›å½’ç³»æ•°è§£è¯»ã€‘")
        for var, coef_info in coefficients.items():
            if var == "const":
                continue
            estimate = coef_info.get("estimate", 0)
            p_value = coef_info.get("p_value", 1.0)
            sig = "æ˜¾è‘—" if p_value < 0.05 else "ä¸æ˜¾è‘—"
            direction = "æ­£å‘" if estimate > 0 else "è´Ÿå‘"
            parts.append(f"  - {var}: ç³»æ•° = {estimate:.4f} ({direction}å½±å“, {sig}, p = {p_value:.4f})")

        # å®é™…æ„ä¹‰æ€»ç»“
        if f_pvalue is not None and f_pvalue < 0.05:
            parts.append("\nğŸ“Š å®é™…æ„ä¹‰ï¼šæ¨¡å‹å…·æœ‰ç»Ÿè®¡å­¦æ„ä¹‰ï¼Œè‡ªå˜é‡å¯¹å› å˜é‡æœ‰é¢„æµ‹ä½œç”¨ã€‚ä½†éœ€æ³¨æ„ï¼š")
            parts.append("  1. ç›¸å…³ä¸ç­‰äºå› æœï¼Œéœ€ç»“åˆç ”ç©¶è®¾è®¡åˆ¤æ–­å› æœå…³ç³»")
            parts.append("  2. æ£€æŸ¥æ®‹å·®æ˜¯å¦ç¬¦åˆæ­£æ€æ€§å’Œæ–¹å·®é½æ€§å‡è®¾")
            parts.append("  3. å…³æ³¨è°ƒæ•´ RÂ² è€ŒéåŸå§‹ RÂ² ä»¥è¯„ä¼°æ¨¡å‹æ³›åŒ–èƒ½åŠ›")
        else:
            parts.append("\nğŸ“Š å®é™…æ„ä¹‰ï¼šæ¨¡å‹æ•´ä½“ä¸æ˜¾è‘—ï¼Œè‡ªå˜é‡æœªèƒ½æœ‰æ•ˆé¢„æµ‹å› å˜é‡ã€‚å»ºè®®ï¼š")
            parts.append("  1. è€ƒè™‘åŠ å…¥å…¶ä»–æ½œåœ¨é¢„æµ‹å˜é‡")
            parts.append("  2. æ£€æŸ¥æ˜¯å¦å­˜åœ¨éçº¿æ€§å…³ç³»")
            parts.append("  3. ç¡®è®¤æ•°æ®è´¨é‡å’Œæ ·æœ¬é‡æ˜¯å¦å……è¶³")

        return "\n".join(parts)

    @staticmethod
    def interpret_mann_whitney(result: dict[str, Any]) -> str:
        """è§£è¯» Mann-Whitney U æ£€éªŒç»“æœã€‚

        Args:
            result: mann_whitney æŠ€èƒ½è¿”å›çš„ data å­—æ®µ

        Returns:
            è§£è¯»æ–‡æœ¬
        """
        p_value = result.get("p_value", 1.0)
        significant = result.get("significant", False)
        u_stat = result.get("u_statistic", 0)
        median1 = result.get("median1")
        median2 = result.get("median2")
        effect_size_r = result.get("effect_size_r")

        parts = ["ã€Mann-Whitney U æ£€éªŒè§£è¯»ã€‘"]
        parts.append("æ³¨ï¼šéå‚æ•°æ£€éªŒï¼Œä¸å‡è®¾æ•°æ®æœä»æ­£æ€åˆ†å¸ƒã€‚")

        if significant:
            parts.append(f"ç»“æœå…·æœ‰ç»Ÿè®¡å­¦æ˜¾è‘—æ€§ (U = {u_stat:.0f}, p = {p_value:.4f} < 0.05)ã€‚")
        else:
            parts.append(f"ç»“æœä¸å…·æœ‰ç»Ÿè®¡å­¦æ˜¾è‘—æ€§ (U = {u_stat:.0f}, p = {p_value:.4f} >= 0.05)ã€‚")

        # ä¸­ä½æ•°æ¯”è¾ƒ
        if median1 is not None and median2 is not None:
            direction = "é«˜äº" if median1 > median2 else "ä½äº"
            parts.append(f"ç¬¬ä¸€ç»„ä¸­ä½æ•° ({median1:.3f}) {direction}ç¬¬äºŒç»„ä¸­ä½æ•° ({median2:.3f})ã€‚")

        # æ•ˆåº”é‡
        if effect_size_r is not None:
            effect = ResultInterpreter._interpret_correlation_strength(effect_size_r)
            parts.append(f"æ•ˆåº”é‡ r = {effect_size_r:.3f}ï¼Œå±äº{effect}ã€‚")

        if significant:
            parts.append("ğŸ“Š å®é™…æ„ä¹‰ï¼šä¸¤ç»„åˆ†å¸ƒå­˜åœ¨æ˜¾è‘—å·®å¼‚ã€‚ç”±äºæ˜¯éå‚æ•°æ£€éªŒï¼Œç»“è®ºé€‚ç”¨äºåˆ†å¸ƒå½¢çŠ¶è€Œä¸ä»…æ˜¯å‡å€¼ã€‚")
        else:
            parts.append("ğŸ“Š å®é™…æ„ä¹‰ï¼šæœªèƒ½æ£€æµ‹åˆ°ä¸¤ç»„åˆ†å¸ƒçš„æ˜¾è‘—å·®å¼‚ã€‚")

        return "\n".join(parts)

    @staticmethod
    def interpret_kruskal_wallis(result: dict[str, Any]) -> str:
        """è§£è¯» Kruskal-Wallis H æ£€éªŒç»“æœã€‚

        Args:
            result: kruskal_wallis æŠ€èƒ½è¿”å›çš„ data å­—æ®µ

        Returns:
            è§£è¯»æ–‡æœ¬
        """
        p_value = result.get("p_value", 1.0)
        significant = result.get("significant", False)
        h_stat = result.get("h_statistic", 0)
        df = result.get("df", 0)
        n_groups = result.get("n_groups", 0)
        eta_squared = result.get("eta_squared")

        parts = ["ã€Kruskal-Wallis H æ£€éªŒè§£è¯»ã€‘"]
        parts.append("æ³¨ï¼šéå‚æ•°æ£€éªŒï¼Œä¸å‡è®¾æ•°æ®æœä»æ­£æ€åˆ†å¸ƒï¼Œé€‚ç”¨äºå¤šç»„æ¯”è¾ƒã€‚")

        if significant:
            parts.append(f"ç»“æœå…·æœ‰ç»Ÿè®¡å­¦æ˜¾è‘—æ€§ (H({df}) = {h_stat:.3f}, p = {p_value:.4f} < 0.05)ã€‚")
            parts.append(f"{n_groups} ä¸ªç»„çš„åˆ†å¸ƒä¸­è‡³å°‘æœ‰ä¸€ç»„ä¸å…¶ä»–ç»„å­˜åœ¨æ˜¾è‘—å·®å¼‚ã€‚")
        else:
            parts.append(f"ç»“æœä¸å…·æœ‰ç»Ÿè®¡å­¦æ˜¾è‘—æ€§ (H({df}) = {h_stat:.3f}, p = {p_value:.4f} >= 0.05)ã€‚")
            parts.append(f"æœªèƒ½æ£€æµ‹åˆ° {n_groups} ä¸ªç»„ä¹‹é—´çš„æ˜¾è‘—å·®å¼‚ã€‚")

        # æ•ˆåº”é‡
        if eta_squared is not None:
            effect = ResultInterpreter._interpret_eta_squared(eta_squared)
            parts.append(f"æ•ˆåº”é‡ Î·Â² = {eta_squared:.3f}ï¼Œå±äº{effect}ã€‚")

        # ä¸­ä½æ•°ä¿¡æ¯
        group_medians = result.get("group_medians", {})
        if group_medians:
            parts.append("\nã€å„ç»„ä¸­ä½æ•°ã€‘")
            for group, median in group_medians.items():
                parts.append(f"  - {group}: {median:.3f}")

        if significant:
            parts.append("\nğŸ“Š å®é™…æ„ä¹‰ï¼šå¤šç»„é—´å­˜åœ¨æ˜¾è‘—å·®å¼‚ã€‚å»ºè®®è¿›è¡Œäº‹åæ£€éªŒï¼ˆå¦‚ Dunn æ£€éªŒï¼‰ç¡®å®šå…·ä½“å“ªäº›ç»„ä¹‹é—´å­˜åœ¨å·®å¼‚ã€‚")
        else:
            parts.append("\nğŸ“Š å®é™…æ„ä¹‰ï¼šå„ç»„åˆ†å¸ƒåœ¨ç»Ÿè®¡ä¸Šæ— æ˜¾è‘—å·®å¼‚ã€‚")

        return "\n".join(parts)

    # ---- è¾…åŠ©æ–¹æ³•ï¼šæ•ˆåº”é‡è§£è¯» ----

    @staticmethod
    def _interpret_cohens_d(d: float) -> str:
        """è§£è¯» Cohen's d æ•ˆåº”é‡ã€‚

        å‚è€ƒæ ‡å‡†ï¼š
        - 0.2: å°æ•ˆåº”
        - 0.5: ä¸­ç­‰æ•ˆåº”
        - 0.8: å¤§æ•ˆåº”
        """
        if d < 0.2:
            return "å¯å¿½ç•¥æ•ˆåº”"
        elif d < 0.5:
            return "å°æ•ˆåº”"
        elif d < 0.8:
            return "ä¸­ç­‰æ•ˆåº”"
        else:
            return "å¤§æ•ˆåº”"

    @staticmethod
    def _interpret_eta_squared(eta2: float) -> str:
        """è§£è¯» eta squared æ•ˆåº”é‡ã€‚

        å‚è€ƒæ ‡å‡†ï¼š
        - 0.01: å°æ•ˆåº”
        - 0.06: ä¸­ç­‰æ•ˆåº”
        - 0.14: å¤§æ•ˆåº”
        """
        if eta2 < 0.01:
            return "å¯å¿½ç•¥æ•ˆåº”"
        elif eta2 < 0.06:
            return "å°æ•ˆåº”"
        elif eta2 < 0.14:
            return "ä¸­ç­‰æ•ˆåº”"
        else:
            return "å¤§æ•ˆåº”"

    @staticmethod
    def _interpret_correlation_strength(r: float) -> str:
        """è§£è¯»ç›¸å…³ç³»æ•°å¼ºåº¦ã€‚

        å‚è€ƒæ ‡å‡†ï¼š
        - 0.1: å¼±ç›¸å…³
        - 0.3: ä¸­ç­‰ç›¸å…³
        - 0.5: å¼ºç›¸å…³
        """
        if r < 0.1:
            return "å¯å¿½ç•¥"
        elif r < 0.3:
            return "å¼±ç›¸å…³"
        elif r < 0.5:
            return "ä¸­ç­‰ç›¸å…³"
        elif r < 0.7:
            return "å¼ºç›¸å…³"
        else:
            return "æå¼ºç›¸å…³"

    @staticmethod
    def _interpret_r_squared(r2: float) -> str:
        """è§£è¯» RÂ² æ•ˆåº”é‡ã€‚

        å‚è€ƒæ ‡å‡†ï¼š
        - 0.02: å°æ•ˆåº”
        - 0.13: ä¸­ç­‰æ•ˆåº”
        - 0.26: å¤§æ•ˆåº”
        """
        if r2 < 0.02:
            return "å¯å¿½ç•¥"
        elif r2 < 0.13:
            return "å°æ•ˆåº”"
        elif r2 < 0.26:
            return "ä¸­ç­‰æ•ˆåº”"
        else:
            return "å¤§æ•ˆåº”"


def interpret_result(test_type: str, result: dict[str, Any]) -> str:
    """æ ¹æ®æ£€éªŒç±»å‹è‡ªåŠ¨é€‰æ‹©è§£è¯»æ–¹æ³•ã€‚

    Args:
        test_type: æ£€éªŒç±»å‹ï¼Œå¦‚ 't_test', 'anova', 'correlation' ç­‰
        result: æ£€éªŒç»“æœæ•°æ®

    Returns:
        è§£è¯»æ–‡æœ¬
    """
    interpreter = ResultInterpreter()

    interpreters = {
        "t_test": interpreter.interpret_t_test,
        "anova": interpreter.interpret_anova,
        "correlation": interpreter.interpret_correlation,
        "regression": interpreter.interpret_regression,
        "mann_whitney": interpreter.interpret_mann_whitney,
        "kruskal_wallis": interpreter.interpret_kruskal_wallis,
    }

    interpret_func = interpreters.get(test_type)
    if interpret_func:
        return interpret_func(result)

    return f"æš‚ä¸æ”¯æŒ {test_type} ç±»å‹çš„ç»“æœè§£è¯»ã€‚"


# ---- Skill æ¥å£ ----

from nini.agent.session import Session
from nini.skills.base import Skill, SkillResult


class InterpretStatisticalResultSkill(Skill):
    """æ™ºèƒ½è§£è¯»ç»Ÿè®¡æ£€éªŒç»“æœï¼Œç”Ÿæˆå®é™…æ„ä¹‰è§£é‡Šã€‚"""

    @property
    def name(self) -> str:
        return "interpret_statistical_result"

    @property
    def category(self) -> str:
        return "statistics"

    @property
    def expose_to_llm(self) -> bool:
        return True

    @property
    def description(self) -> str:
        return (
            "æ™ºèƒ½è§£è¯»ç»Ÿè®¡æ£€éªŒç»“æœï¼Œè‡ªåŠ¨ç”ŸæˆåŒ…å«ç»Ÿè®¡æ„ä¹‰å’Œå®é™…æ„ä¹‰çš„è§£è¯»æ–‡æœ¬ã€‚\n"
            "æ”¯æŒï¼štæ£€éªŒã€ANOVAã€ç›¸å…³åˆ†æã€å›å½’åˆ†æã€Mann-Whitney Uæ£€éªŒã€Kruskal-Wallis Hæ£€éªŒã€‚"
        )

    @property
    def parameters(self) -> dict[str, Any]:
        return {
            "type": "object",
            "properties": {
                "test_type": {
                    "type": "string",
                    "enum": ["t_test", "anova", "correlation", "regression", "mann_whitney", "kruskal_wallis"],
                    "description": "ç»Ÿè®¡æ£€éªŒç±»å‹",
                },
                "result": {
                    "type": "object",
                    "description": "ç»Ÿè®¡æ£€éªŒç»“æœæ•°æ®ï¼ˆå³æŠ€èƒ½è¿”å›çš„ data å­—æ®µï¼‰",
                },
            },
            "required": ["test_type", "result"],
        }

    async def execute(self, session: Session, **kwargs: Any) -> SkillResult:
        test_type = kwargs.get("test_type")
        result = kwargs.get("result")

        if not test_type or not result:
            return SkillResult(
                success=False,
                message="è¯·æä¾› test_type å’Œ result å‚æ•°"
            )

        try:
            interpretation = interpret_result(test_type, result)
            return SkillResult(
                success=True,
                data={"interpretation": interpretation},
                message="ç»Ÿè®¡ç»“æœè§£è¯»å®Œæˆ"
            )
        except Exception as e:
            return SkillResult(
                success=False,
                message=f"è§£è¯»å¤±è´¥: {e}"
            )
