"""å·®å¼‚åˆ†æèƒ½åŠ›å®ç°ã€‚

æ‰§è¡Œå®Œæ•´çš„å·®å¼‚åˆ†ææµç¨‹ï¼š
1. æ•°æ®è´¨é‡æ£€æŸ¥
2. æ­£æ€æ€§æ£€éªŒ
3. æ–¹å·®é½æ€§æ£€éªŒï¼ˆå¤šç»„æ—¶ï¼‰
4. è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„ç»Ÿè®¡æ£€éªŒ
5. æ•ˆåº”é‡è®¡ç®—
6. äº‹åæ£€éªŒï¼ˆå¦‚éœ€è¦ï¼‰
7. å¯è§†åŒ–
8. ç”Ÿæˆè§£é‡Šæ€§æŠ¥å‘Š
"""

from __future__ import annotations

from dataclasses import dataclass, field
from typing import TYPE_CHECKING, Any

from scipy import stats

if TYPE_CHECKING:
    from nini.agent.session import Session
    from nini.tools.base import SkillResult


@dataclass
class DifferenceAnalysisResult:
    """å·®å¼‚åˆ†æç»“æœã€‚"""

    success: bool = False
    message: str = ""

    # æ•°æ®ç‰¹å¾
    n_groups: int = 0
    group_sizes: dict[str, int] = field(default_factory=dict)
    group_means: dict[str, float] = field(default_factory=dict)

    # å‰ææ£€éªŒ
    normality_tests: dict[str, Any] = field(default_factory=dict)
    equal_variance_test: dict[str, Any] | None = None

    # é€‰æ‹©çš„ç»Ÿè®¡æ–¹æ³•
    selected_method: str = ""
    method_reason: str = ""

    # ç»Ÿè®¡ç»“æœ
    test_statistic: float | None = None
    p_value: float | None = None
    degrees_of_freedom: int | None = None
    effect_size: float | None = None
    effect_type: str = ""
    significant: bool = False

    # äº‹åæ£€éªŒï¼ˆå¤šç»„æ—¶ï¼‰
    post_hoc: list[dict[str, Any]] | None = None

    # å¯è§†åŒ–
    chart_artifact: dict[str, Any] | None = None

    # è§£é‡Šæ€§æŠ¥å‘Š
    interpretation: str = ""

    def to_dict(self) -> dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸ã€‚"""
        return {
            "success": self.success,
            "message": self.message,
            "n_groups": self.n_groups,
            "group_sizes": self.group_sizes,
            "group_means": self.group_means,
            "normality_tests": self.normality_tests,
            "equal_variance_test": self.equal_variance_test,
            "selected_method": self.selected_method,
            "method_reason": self.method_reason,
            "test_statistic": self.test_statistic,
            "p_value": self.p_value,
            "degrees_of_freedom": self.degrees_of_freedom,
            "effect_size": self.effect_size,
            "effect_type": self.effect_type,
            "significant": self.significant,
            "post_hoc": self.post_hoc,
            "chart_artifact": self.chart_artifact,
            "interpretation": self.interpretation,
        }


class DifferenceAnalysisCapability:
    """
    å·®å¼‚åˆ†æèƒ½åŠ›ã€‚

    è‡ªåŠ¨æ‰§è¡Œå®Œæ•´çš„å·®å¼‚åˆ†ææµç¨‹ï¼ŒåŒ…æ‹¬ï¼š
    - æ•°æ®è´¨é‡æ£€æŸ¥
    - æ­£æ€æ€§æ£€éªŒï¼ˆShapiro-Wilkï¼‰
    - æ–¹å·®é½æ€§æ£€éªŒï¼ˆLeveneï¼‰
    - è‡ªåŠ¨é€‰æ‹©ç»Ÿè®¡æ–¹æ³•
    - æ•ˆåº”é‡è®¡ç®—
    - å¯è§†åŒ–
    - è§£é‡Šæ€§æŠ¥å‘Š

    ä½¿ç”¨æ–¹æ³•ï¼š
        capability = DifferenceAnalysisCapability()
        result = await capability.execute(
            session,
            dataset_name="my_data",
            value_column="score",
            group_column="group"
        )
    """

    def __init__(self, registry: Any | None = None) -> None:
        """åˆå§‹åŒ–å·®å¼‚åˆ†æèƒ½åŠ›ã€‚

        Args:
            registry: ToolRegistry å®ä¾‹ï¼Œå¦‚æœä¸º None åˆ™å°è¯•è·å–å…¨å±€ registry
        """
        self.name = "difference_analysis"
        self.display_name = "å·®å¼‚åˆ†æ"
        self.description = "æ¯”è¾ƒä¸¤ç»„æˆ–å¤šç»„æ•°æ®çš„å·®å¼‚"
        self.icon = "ğŸ”¬"
        self._registry = registry

    async def execute(
        self,
        session: Session,
        *,
        dataset_name: str,
        value_column: str,
        group_column: str | None = None,
        test_value: float | None = None,
        alpha: float = 0.05,
        auto_select_method: bool = True,
        **kwargs: Any,
    ) -> DifferenceAnalysisResult:
        """
        æ‰§è¡Œå·®å¼‚åˆ†æã€‚

        Args:
            session: ä¼šè¯å¯¹è±¡
            dataset_name: æ•°æ®é›†åç§°
            value_column: æ•°å€¼åˆ—å
            group_column: åˆ†ç»„åˆ—åï¼ˆä¸¤ç»„æˆ–å¤šç»„æ¯”è¾ƒæ—¶ä½¿ç”¨ï¼‰
            test_value: æ£€éªŒå€¼ï¼ˆå•æ ·æœ¬æ£€éªŒæ—¶ä½¿ç”¨ï¼‰
            alpha: æ˜¾è‘—æ€§æ°´å¹³ï¼ˆé»˜è®¤ 0.05ï¼‰
            auto_select_method: æ˜¯å¦è‡ªåŠ¨é€‰æ‹©ç»Ÿè®¡æ–¹æ³•

        Returns:
            å·®å¼‚åˆ†æç»“æœ
        """
        result = DifferenceAnalysisResult()

        # Step 1: æ•°æ®éªŒè¯
        if not await self._validate_data(
            session, dataset_name, value_column, group_column, test_value, result
        ):
            return result

        # Step 2: è·å–æ•°æ®ç‰¹å¾
        df = session.datasets.get(dataset_name)
        if group_column:
            groups_data = self._extract_groups(df, value_column, group_column)
            result.n_groups = len(groups_data)
            result.group_sizes = {name: len(data) for name, data in groups_data.items()}
            result.group_means = {name: float(data.mean()) for name, data in groups_data.items()}
        else:
            # å•æ ·æœ¬æ£€éªŒ
            data = df[value_column].dropna()
            result.n_groups = 1
            result.group_sizes = {"sample": len(data)}
            result.group_means = {"sample": float(data.mean())}

        # Step 3: å‰ææ£€éªŒ
        if auto_select_method:
            assumptions = await self._check_assumptions(
                session, dataset_name, value_column, group_column, alpha
            )
            result.normality_tests = assumptions.get("normality", {})
            result.equal_variance_test = assumptions.get("equal_variance")

            # Step 4: è‡ªåŠ¨é€‰æ‹©ç»Ÿè®¡æ–¹æ³•
            selected_method = self._select_statistical_method(
                result.n_groups,
                assumptions,
                auto_select_method,
            )
            result.selected_method = selected_method
            result.method_reason = self._get_method_reason(selected_method, assumptions)
        else:
            # ä½¿ç”¨é»˜è®¤æ–¹æ³•
            if result.n_groups == 1:
                result.selected_method = "t_test"
            elif result.n_groups == 2:
                result.selected_method = "t_test"
            else:
                result.selected_method = "anova"
            result.method_reason = "ä½¿ç”¨é»˜è®¤æ–¹æ³•ï¼ˆæœªå¯ç”¨è‡ªåŠ¨é€‰æ‹©ï¼‰"

        # Step 5: æ‰§è¡Œç»Ÿè®¡æ£€éªŒ
        stat_result = await self._execute_statistical_test(
            session,
            dataset_name,
            value_column,
            group_column,
            test_value,
            result.selected_method,
            **kwargs,
        )

        # Note: registry.execute returns a dict, not SkillResult
        if isinstance(stat_result, dict):
            if not stat_result.get("success"):
                result.message = f"ç»Ÿè®¡æ£€éªŒå¤±è´¥: {stat_result.get('message', 'æœªçŸ¥é”™è¯¯')}"
                return result
        elif hasattr(stat_result, "success") and not stat_result.success:
            result.message = f"ç»Ÿè®¡æ£€éªŒå¤±è´¥: {stat_result.message}"
            return result

        # æå–ç»Ÿè®¡ç»“æœ
        self._extract_statistical_results(result, stat_result)

        # Step 6: å¯è§†åŒ–
        chart_result = await self._create_visualization(
            session, dataset_name, value_column, group_column, result.selected_method
        )
        # å¤„ç† dict æˆ– SkillResult ç±»å‹
        if isinstance(chart_result, dict):
            if chart_result.get("success") and chart_result.get("artifacts"):
                artifacts = chart_result["artifacts"]
                result.chart_artifact = artifacts[0] if artifacts else None
        elif chart_result.success and chart_result.artifacts:
            result.chart_artifact = chart_result.artifacts[0] if chart_result.artifacts else None

        # Step 7: ç”Ÿæˆè§£é‡Š
        result.interpretation = self._generate_interpretation(result)
        result.success = True
        result.message = "å·®å¼‚åˆ†æå®Œæˆ"

        return result

    async def _validate_data(
        self,
        session: Session,
        dataset_name: str,
        value_column: str,
        group_column: str | None,
        test_value: float | None,
        result: DifferenceAnalysisResult,
    ) -> bool:
        """éªŒè¯æ•°æ®æœ‰æ•ˆæ€§ã€‚"""
        df = session.datasets.get(dataset_name)
        if df is None:
            result.message = f"æ•°æ®é›† '{dataset_name}' ä¸å­˜åœ¨"
            return False

        if value_column not in df.columns:
            result.message = f"åˆ— '{value_column}' ä¸å­˜åœ¨"
            return False

        if group_column and group_column not in df.columns:
            result.message = f"åˆ†ç»„åˆ— '{group_column}' ä¸å­˜åœ¨"
            return False

        if group_column is None and test_value is None:
            result.message = "è¯·æŒ‡å®š group_columnï¼ˆç»„é—´æ¯”è¾ƒï¼‰æˆ– test_valueï¼ˆå•æ ·æœ¬æ£€éªŒï¼‰"
            return False

        return True

    def _extract_groups(self, df, value_column: str, group_column: str) -> dict[str, Any]:
        """æå–å„ç»„æ•°æ®ã€‚"""
        groups = {}
        for group_name in df[group_column].dropna().unique():
            group_data = df[df[group_column] == group_name][value_column].dropna()
            if len(group_data) > 0:
                groups[str(group_name)] = group_data
        return groups

    async def _check_assumptions(
        self,
        session: Session,
        dataset_name: str,
        value_column: str,
        group_column: str | None,
        alpha: float,
    ) -> dict[str, Any]:
        """æ£€æŸ¥ç»Ÿè®¡å‰æå‡è®¾ã€‚"""
        assumptions = {"normality": {}, "equal_variance": None}

        df = session.datasets.get(dataset_name)
        if df is None:
            return assumptions

        if group_column:
            groups_data = self._extract_groups(df, value_column, group_column)
        else:
            groups_data = {"sample": df[value_column].dropna()}

        # ç›´æ¥åœ¨ Capability å†…éƒ¨å®Œæˆæœ€å°å‰ææ£€éªŒï¼Œé¿å…ä¾èµ–ä¸å­˜åœ¨çš„ Tool åè®®ã€‚
        for group_name, group_data in groups_data.items():
            if len(group_data) < 3 or len(group_data) > 5000:
                assumptions["normality"][group_name] = {
                    "tested": False,
                    "reason": "æ ·æœ¬é‡ä¸åœ¨ Shapiro-Wilk é€‚ç”¨èŒƒå›´å†…",
                }
                continue
            try:
                statistic, p_value = stats.shapiro(group_data)
                assumptions["normality"][group_name] = {
                    "tested": True,
                    "statistic": float(statistic),
                    "p_value": float(p_value),
                    "normal": bool(p_value > alpha),
                }
            except Exception as exc:
                assumptions["normality"][group_name] = {
                    "tested": False,
                    "reason": f"æ­£æ€æ€§æ£€éªŒå¤±è´¥: {exc}",
                }

        if len(groups_data) >= 2:
            try:
                statistic, p_value = stats.levene(*groups_data.values())
                assumptions["equal_variance"] = {
                    "tested": True,
                    "statistic": float(statistic),
                    "p_value": float(p_value),
                    "equal_variance": bool(p_value > alpha),
                }
            except Exception as exc:
                assumptions["equal_variance"] = {
                    "tested": False,
                    "reason": f"æ–¹å·®é½æ€§æ£€éªŒå¤±è´¥: {exc}",
                }

        return assumptions

    def _select_statistical_method(
        self,
        n_groups: int,
        assumptions: dict[str, Any],
        auto_select: bool,
    ) -> str:
        """æ ¹æ®å‰ææ£€éªŒç»“æœé€‰æ‹©ç»Ÿè®¡æ–¹æ³•ã€‚"""
        if not auto_select:
            if n_groups == 1:
                return "t_test"
            elif n_groups == 2:
                return "t_test"
            else:
                return "anova"

        # æ£€æŸ¥æ­£æ€æ€§
        normality = assumptions.get("normality", {})
        is_normal = True
        if normality:
            # å¦‚æœæ‰€æœ‰ç»„çš„ p å€¼éƒ½ > 0.05ï¼Œè®¤ä¸ºç¬¦åˆæ­£æ€æ€§
            for col, result in normality.items():
                if not isinstance(result, dict):
                    continue
                if result.get("tested") is False:
                    continue
                if result.get("p_value", 1) < 0.05:
                    is_normal = False
                    break

        # é€‰æ‹©æ–¹æ³•
        if n_groups == 1:
            return "t_test" if is_normal else "not_supported"  # å•æ ·æœ¬éå‚æš‚æœªå®ç°
        elif n_groups == 2:
            return "t_test" if is_normal else "mann_whitney"
        else:
            # å¤šç»„
            equal_variance = assumptions.get("equal_variance")
            if (
                isinstance(equal_variance, dict)
                and equal_variance.get("tested") is not False
                and equal_variance.get("p_value", 1) < 0.05
            ):
                # æ–¹å·®ä¸é½
                return "kruskal_wallis"
            return "anova" if is_normal else "kruskal_wallis"

    def _get_method_reason(self, method: str, assumptions: dict[str, Any]) -> str:
        """è·å–æ–¹æ³•é€‰æ‹©çš„åŸå› è¯´æ˜ã€‚"""
        reasons = {
            "t_test": "æ•°æ®ç¬¦åˆæ­£æ€åˆ†å¸ƒå‡è®¾ï¼Œä½¿ç”¨ t æ£€éªŒ",
            "mann_whitney": "æ•°æ®ä¸ç¬¦åˆæ­£æ€åˆ†å¸ƒï¼Œä½¿ç”¨ Mann-Whitney U æ£€éªŒï¼ˆéå‚æ•°æ–¹æ³•ï¼‰",
            "anova": "æ•°æ®ç¬¦åˆæ­£æ€åˆ†å¸ƒå‡è®¾ï¼Œä½¿ç”¨æ–¹å·®åˆ†æï¼ˆANOVAï¼‰",
            "kruskal_wallis": "æ•°æ®ä¸ç¬¦åˆæ­£æ€åˆ†å¸ƒï¼Œä½¿ç”¨ Kruskal-Wallis H æ£€éªŒï¼ˆéå‚æ•°æ–¹æ³•ï¼‰",
            "not_supported": "å½“å‰æ–¹æ³•æš‚ä¸æ”¯æŒ",
        }
        return reasons.get(method, "ä½¿ç”¨é»˜è®¤æ–¹æ³•")

    def _get_registry(self) -> Any:
        """è·å–å·¥å…·æ³¨å†Œä¸­å¿ƒã€‚"""
        if self._registry is not None:
            return self._registry
        # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯ä¾èµ–
        from nini.tools.registry import create_default_tool_registry

        return create_default_tool_registry()

    async def _execute_statistical_test(
        self,
        session: Session,
        dataset_name: str,
        value_column: str,
        group_column: str | None,
        test_value: float | None,
        method: str,
        **kwargs: Any,
    ) -> SkillResult:
        """æ‰§è¡Œç»Ÿè®¡æ£€éªŒã€‚"""
        registry = self._get_registry()

        if method == "t_test":
            if test_value is not None:
                # å•æ ·æœ¬ t æ£€éªŒ
                return await registry.execute(
                    "t_test",
                    session,
                    dataset_name=dataset_name,
                    value_column=value_column,
                    test_value=test_value,
                    **kwargs,
                )
            else:
                # ç‹¬ç«‹æ ·æœ¬ t æ£€éªŒ
                return await registry.execute(
                    "t_test",
                    session,
                    dataset_name=dataset_name,
                    value_column=value_column,
                    group_column=group_column,
                    **kwargs,
                )
        elif method == "mann_whitney":
            return await registry.execute(
                "mann_whitney",
                session,
                dataset_name=dataset_name,
                value_column=value_column,
                group_column=group_column,
                **kwargs,
            )
        elif method == "anova":
            return await registry.execute(
                "anova",
                session,
                dataset_name=dataset_name,
                value_column=value_column,
                group_column=group_column,
                **kwargs,
            )
        elif method == "kruskal_wallis":
            return await registry.execute(
                "kruskal_wallis",
                session,
                dataset_name=dataset_name,
                value_column=value_column,
                group_column=group_column,
                **kwargs,
            )
        else:
            from nini.tools.base import SkillResult

            return SkillResult(success=False, message=f"ä¸æ”¯æŒçš„æ–¹æ³•: {method}")

    def _extract_statistical_results(
        self, result: DifferenceAnalysisResult, stat_result: SkillResult | dict[str, Any]
    ) -> None:
        """ä»ç»Ÿè®¡ç»“æœä¸­æå–å…³é”®ä¿¡æ¯ã€‚"""
        # å¤„ç† dict ç±»å‹ç»“æœï¼ˆToolRegistry.execute è¿”å› dictï¼‰
        if isinstance(stat_result, dict):
            if not stat_result.get("success") or not stat_result.get("data"):
                return
            data = stat_result["data"]
        else:
            if not stat_result.success or not stat_result.data:
                return
            data = stat_result.data
        result.test_statistic = (
            data.get("t_statistic")
            or data.get("f_statistic")
            or data.get("u_statistic")
            or data.get("h_statistic")
        )
        result.p_value = data.get("p_value")
        result.degrees_of_freedom = data.get("df") or data.get("df_between")
        result.effect_size = data.get("cohens_d") or data.get("eta_squared") or data.get("r")
        result.effect_type = (
            "cohens_d"
            if "cohens_d" in data
            else "eta_squared" if "eta_squared" in data else "r" if "r" in data else ""
        )
        result.significant = data.get("significant", False)
        result.post_hoc = data.get("post_hoc")

    async def _create_visualization(
        self,
        session: Session,
        dataset_name: str,
        value_column: str,
        group_column: str | None,
        method: str,
    ) -> SkillResult:
        """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨ã€‚"""
        registry = self._get_registry()

        # é€‰æ‹©å›¾è¡¨ç±»å‹
        if group_column:
            if method in ["anova", "kruskal_wallis"]:
                chart_type = "box"
            else:
                chart_type = "box"
        else:
            chart_type = "histogram"

        return await registry.execute(
            "create_chart",
            session,
            dataset_name=dataset_name,
            chart_type=chart_type,
            x_column=group_column,
            y_column=value_column,
            title=f"{self.display_name} - {value_column}",
        )

    def _generate_interpretation(self, result: DifferenceAnalysisResult) -> str:
        """ç”Ÿæˆè§£é‡Šæ€§æŠ¥å‘Šã€‚"""
        parts = []

        # æ–¹æ³•è¯´æ˜
        parts.append(f"## åˆ†ææ–¹æ³•")
        parts.append(f"é€‰æ‹©æ–¹æ³•: {result.selected_method}")
        parts.append(f"é€‰æ‹©ç†ç”±: {result.method_reason}")

        # ç»Ÿè®¡ç»“æœ
        parts.append(f"\n## ç»Ÿè®¡ç»“æœ")
        if result.n_groups == 2:
            parts.append(f"æ¯”è¾ƒä¸¤ç»„æ•°æ®å·®å¼‚")
        elif result.n_groups > 2:
            parts.append(f"æ¯”è¾ƒ {result.n_groups} ç»„æ•°æ®å·®å¼‚")

        if result.test_statistic is not None:
            parts.append(f"æ£€éªŒç»Ÿè®¡é‡: {result.test_statistic:.3f}")
        if result.p_value is not None:
            parts.append(f"p å€¼: {result.p_value:.4f}")
        if result.effect_size is not None:
            parts.append(f"æ•ˆåº”é‡ ({result.effect_type}): {result.effect_size:.3f}")

        # ç»“è®º
        parts.append(f"\n## ç»“è®º")
        if result.significant:
            parts.append(f"ç»“æœæ˜¾è‘— (p < 0.05)ï¼Œæ‹’ç»åŸå‡è®¾ï¼Œè®¤ä¸ºå„ç»„é—´å­˜åœ¨æ˜¾è‘—å·®å¼‚ã€‚")
            # æ•ˆåº”é‡è§£é‡Š
            if result.effect_size is not None:
                if result.effect_type == "cohens_d":
                    if abs(result.effect_size) < 0.2:
                        parts.append("æ•ˆåº”é‡è¾ƒå° (Cohen's d < 0.2)ã€‚")
                    elif abs(result.effect_size) < 0.5:
                        parts.append("æ•ˆåº”é‡ä¸­ç­‰ (Cohen's d = 0.2-0.5)ã€‚")
                    elif abs(result.effect_size) < 0.8:
                        parts.append("æ•ˆåº”é‡è¾ƒå¤§ (Cohen's d = 0.5-0.8)ã€‚")
                    else:
                        parts.append("æ•ˆåº”é‡å¾ˆå¤§ (Cohen's d > 0.8)ã€‚")
        else:
            parts.append(
                f"ç»“æœä¸æ˜¾è‘— (p = {result.p_value:.4f} >= 0.05)ï¼Œæ— æ³•æ‹’ç»åŸå‡è®¾ï¼Œæœªå‘ç°å„ç»„é—´å­˜åœ¨æ˜¾è‘—å·®å¼‚ã€‚"
            )

        # äº‹åæ£€éªŒ
        if result.post_hoc:
            parts.append(f"\n## äº‹åæ£€éªŒ (Tukey HSD)")
            for comp in result.post_hoc[:5]:  # æœ€å¤šæ˜¾ç¤º 5 ä¸ª
                g1, g2 = comp.get("group1"), comp.get("group2")
                p = comp.get("p_value")
                sig = "æ˜¾è‘—" if comp.get("significant") else "ä¸æ˜¾è‘—"
                parts.append(f"- {g1} vs {g2}: p = {p:.4f} ({sig})")

        return "\n".join(parts)
